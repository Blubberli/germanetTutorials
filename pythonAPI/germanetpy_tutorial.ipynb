{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyGermanet Tutorial\n",
    "\n",
    "The following tutorial shows some examples of how to use the Python API for Germanet. Germanet is a lexical-sematic \n",
    "net that relates German nouns, verbs and adjectives semantically by grouping lexical units that express\n",
    "the same concept into synsets. \n",
    "\n",
    "With the Python API we can extract synsets and lexical units for a given word and inspect different properties and related\n",
    "synsets / lexunits. To use the API you can install it with pip:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install germanetpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Whenever you want to use the API, the first thing you would do is to create a GermaNet object as this loads the data and provides access to it. The data (all XML files) have to be stored in one directory which has to be specified as the first argument when you construct the GermaNet object. If you want to run this code, put your XML files in a \"germanet_data\" directory in your home directory or change the path to the location on your computer. The API also provides methods to compute semantic similarity / relatedness between words (Synsets). To be able to use all of them you have to provide frequency lists for each word category. These lists can be downloaded from: <!-- where? -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_path = str(Path.home()) + \"/germanet_data\"\n",
    "frequencylist_nouns = data_path + \"/noun_freqs_decow14_16.txt\"\n",
    "from pathlib import Path\n",
    "from germanetpy.germanet import Germanet\n",
    "\n",
    "germanet = Germanet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The data has been loaded and we can now use the API to extract specific information from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to inspect synset information for a single word input\n",
    "\n",
    "Let's consider the input word *Fußball* 'football'. The following shows how to extract all synsets given an input word. Many words are ambiguous; *Fußball* belongs to two synsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synsets = germanet.get_synsets_by_orthform(\"Fußball\")\n",
    "# the length of the retrieved list is equal to the number of possible senses for a word, in this case 2\n",
    "len(fussball_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string representations include the lexical units, which can be helpful when you want to select\n",
    "a specific meaning for a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in fussball_synsets:\n",
    "    print(synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, let's say we are interested in the sense of *Fußball* which is synonymous with *Fußballspiel* &mdash; that is, the game rather than the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset = germanet.get_synset_by_id('s21624')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every synset has a number of properties that can be extracted. Each synset has a unique id, which is the character\n",
    "'s' followed by a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synset can have one of three possible word categories (verb, noun, adjective). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.word_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the word categories the semantic space is divided into a number of semantic fields. (e.g *Besitz*,\n",
    "*Kommunikation*, *Geschehen*...), called `word_class`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.word_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Synsets are related to other synsets via conceptual relations. The most important relation is the hypernymy\n",
    "/ hyponymy relation. Direct hypernyms of a synset (one level above) and hyponyms (one level below) can be accessed through separate fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.direct_hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.direct_hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All conceptually related synsets are stored in the `relations` field:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation, synsets in fussball_synset.relations.items():\n",
    "    print(\"\\nRelation: %s\" % relation)\n",
    "    print(synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that *Fußball* has exactly one hypernym and several hyponyms. It is also possible to list all <!-- transitive? --> hypernyms\n",
    "from *Fußball* to the top node (root node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.all_hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The level where the *Fußball* synset is attached to the Graph is called its depth. <!-- maybe explain here why the method is called min_depth, namely, a synset can have multiple depths because it can have multiple hypernyms? -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.min_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check whether *Fußball* is the root or a leaf of the GermaNet graph (although of course\n",
    "we already know that this is not case, as it has both hypernyms and hyponyms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.is_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.is_leaf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Use the semantic utils to measure semantic similarity / relatedness\n",
    "\n",
    "You can also use the API to compare a synset with another synset. These methods work only for two synsets that have the same word category, for example for two nouns. There are two different types of similarity measures:\n",
    "- path-based measures\n",
    "- information-content-based measures\n",
    "\n",
    "Path-based measures compute the semantic relatedness between two concepts based on the shortest path between two synsets in the hypernym relation. The shortest path length is the minimal number of nodes forming a path between the two synsets in the relation. Different measures weigh or normalize the path-length in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we will look at the simple path distance between two synsets.\n",
    "\n",
    "Let's say you would like to know how *Fußball* and *Tennis* are related within \n",
    "GermaNet. You first need to extract the synset for *Tennis*. Then you can check whether *Tennis* and *Fußball* share any hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tennis_synsets = germanet.get_synsets_by_orthform(\"Tennis\")\n",
    "tennis_synset = tennis_synsets[0]\n",
    "fussball_synset.common_hypernyms(tennis_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then extract the shortest path you can walk from *Fußball* to end up at *Tennis*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.shortest_path(tennis_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extract the distance between *Fußball* and *Tennis* (in this case the path length). Synsets that are more similar will have a shorter distance than unrelated synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.shortest_path_distance(tennis_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Example for path-based measures\n",
    "\n",
    "The following example shows how to use path-based semantic relatedness measures to check whether *Trompete* (trumpet) is more closely related to *Posaune* (trombone) than to *Flöte* (flute) and how to disambiguate *Flügel* (wing, blade, grand) in the context of *Klavier* (piano). \n",
    "\n",
    "To use the path-based semantic relatedness measures you have to initialize a `PathBasedRelatedness` object. This object takes the longest possible shortest distance and a Synset pair that is maximally apart as argument. If not given, this synset pair will be computed on the fly, but the computation might take some time, especially for nouns.\n",
    "\n",
    "As mentioned above, these measures only work for synsets that belong to the same word category, which has to be specified in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from germanetpy.path_based_relatedness_measures import PathBasedRelatedness\n",
    "from germanetpy.synset import WordCategory\n",
    "\n",
    "# First, construct a path-based similarity object. \n",
    "# The johannis_wurm and leber_trans synsets are maximally far apart among nouns:\n",
    "johannis_wurm = germanet.get_synset_by_id(\"s49774\")\n",
    "leber_trans = germanet.get_synset_by_id(\"s83979\")\n",
    "relatedness_calculator = PathBasedRelatedness(germanet=germanet, category=WordCategory.nomen, max_len=35,\n",
    "                                              max_depth=20, synset_pair=(johannis_wurm, leber_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `relatedness_calculator` object to find out whether *Trompete* (trumpet) is more closely related to *Posaune* (trombone) or to *Flöte* (flute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trompete = germanet.get_synsets_by_orthform(\"Trompete\").pop()\n",
    "flöte = germanet.get_synsets_by_orthform(\"Flöte\").pop()\n",
    "posaune = germanet.get_synsets_by_orthform(\"Posaune\").pop()\n",
    "trompete_posaune = relatedness_calculator.simple_path(trompete, posaune)\n",
    "trompete_flöte = relatedness_calculator.simple_path(trompete, flöte)\n",
    "\n",
    "trompete_posaune > trompete_flöte "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path based relatedness measures can also be used to disambiguate word senses. This example shows how to find the sense of *Flügel* (wing, blade, grand) which is most similar to *Klavier* (piano) according to three different path-based measures:. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Klavier = germanet.get_synsets_by_orthform(\"Klavier\").pop()\n",
    "Flügel_synsets = germanet.get_synsets_by_orthform(\"Flügel\")\n",
    "\n",
    "results = []\n",
    "highest_sim_simple = 0.0\n",
    "highest_sim_leacock = 0.0\n",
    "highest_sim_wu = 0.0\n",
    "most_similar_synset = None\n",
    "\n",
    "for synset in Flügel_synsets:\n",
    "    if synset.word_category == WordCategory.nomen:\n",
    "        sim_simple = relatedness_calculator.simple_path(synset, Klavier, normalize=True)\n",
    "        sim_leacock = relatedness_calculator.leacock_chodorow(synset, Klavier, normalize=True)\n",
    "        sim_wu = relatedness_calculator.wu_and_palmer(synset, Klavier, normalize=True)\n",
    "        results.append([synset.id, sim_simple, sim_leacock, sim_wu])\n",
    "        \n",
    "        if sim_simple > highest_sim_simple and sim_leacock > highest_sim_leacock and sim_wu > highest_sim_wu :\n",
    "            highest_sim_simple = sim_simple\n",
    "            highest_sim_leacock = sim_leacock\n",
    "            highest_sim_wu = sim_wu\n",
    "            most_similar_synset = synset\n",
    "\n",
    "most_similar_synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this is the most similar synset by looking at all the similarity results in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "results_header = (\"| Synset | Simple Path | Leacock and Chodorow | Wu and Palmer |\\n\" +\n",
    "                  \"|--------|-------------|----------------------|---------------|\\n\")\n",
    "\n",
    "results_table = results_header + \"\".join([\"|{}|{}|{}|{}|\\n\".format(*result) for result in results])\n",
    "md(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Example for IC-based measures\n",
    "\n",
    "One problem with path-based measures is that paths of the same length in the hypernym relation can correspond to very different intuitive semantic \"distances\".\n",
    "Measures based on *information content* (IC) seek to solve this problem by augmenting information about the structural distances in the hypernym relation with information about word frequencies. \n",
    "The word frequencies are used to compute the information content, which grades concepts from more specific to more general. If a very specific synset is compared to a very general one, the relatedness will be low. The relatedness of two synsets measured based on the information content of their least common subsumer (the lowest synset in the hierarchy that is hypernym to both synsets).\n",
    "\n",
    "To use these measures, you have to create an `ICBasedSimilarity` object that takes frequency lists as an additional argument. These lists contain the raw frequencies of the nouns, adjectives and verbs that are in Germanet, based on a very large corpus. You can use either the provided frequency lists or your own lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germanetpy.icbased_similarity import ICBasedSimilarity\n",
    "\n",
    "relatedness_nouns = ICBasedSimilarity(germanet=germanet, \n",
    "                                      wordcategory=WordCategory.nomen,\n",
    "                                      path=frequencylist_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet shows the advantage of the IC-based measures. While path-based measures would classify the words *Pflanze* 'plant' and *Tier* 'animal' as being almost as similar as the words *Roteiche* 'red oak' and *Steineiche* 'holm oak', the IC-based measures distinguish whether two synsets are very general or more specific and consequently assign a higher similarity score to the second pair of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first word pair:\n",
    "pflanze = germanet.get_synset_by_id(\"s44960\")\n",
    "tier = germanet.get_synset_by_id(\"s48805\")\n",
    "\n",
    "# second word pair:\n",
    "roteiche = germanet.get_synset_by_id(\"s46054\")\n",
    "steineiche = germanet.get_synset_by_id(\"s46056\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a path-based measure between these word pairs yields almost the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_calculator.leacock_chodorow(pflanze, tier, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_calculator.leacock_chodorow(roteiche, steineiche, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But an IC-based measure clearly distinguishes the two pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_nouns.resnik(pflanze, tier, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_nouns.resnik(roteiche, steineiche, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "For a more convenient search through the ontology and the semantic relatedness computation, you can use the GermaNet web application \"Rover\":\n",
    "https://weblicht.sfs.uni-tuebingen.de/rover/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspect Lexical Units\n",
    "Every synset contains one ore several Lexical Units. The list of Lexical Units (lexunit) can be accessed for any synset. Let's inspect the lexical units for *Fußball* 'football':\n",
    "We have the lexunit *Fußballspiel* 'football match', the lexunit *Fußball* 'football' and the lexunit *Fußballsport* 'soccer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.lexunits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every lexical unit has a number of orthographical forms. There are four different orthographical forms but not every \n",
    "lexical unit has an entry for all of them:\n",
    "* main orth. form\n",
    "* orth. variation\n",
    "* old orth. form\n",
    "* old orth. variation\n",
    "\n",
    "We can see that the lexunit for *Fußball* only has one orth form, but that one of its related synsets *Fußballklub* 'football club' has the \n",
    "orthographical variation *Fußballkclub*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit = germanet.get_lexunit_by_id(\"l29777\")\n",
    "fussball_unit.get_all_orthforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussballclub_unit = germanet.get_lexunit_by_id(\"l32423\")\n",
    "fussballclub_unit.get_all_orthforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussballclub_unit.orthvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Fußball* is a compound noun, which are very frequent in the German language. GermaNet stores information about the \n",
    "compound, for example that *Fuß* 'foot' is the modifier and *ball* 'ball' is the head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit.compound_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units are related to other lexical units by different lexical relations. The most common and most general \n",
    "lexical relation is synonymy (i.e., the relation which groups lexical units into synsets), but there are other lexical relations in GermaNet as well. For example, for some compounds there has been work\n",
    "on annotating the relation between the compound and the modifier. In this example the compound *Fußball* has the manner of functioning *Fuß*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_unit.relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relations can be unidirectional (e.g., the relation \"has manner of functioning\" goes from *Fußball*\n",
    "to *Fuß*, but not the other way around). The relations can also be bidirectional (e.g., *Fußball* and *Fußballspiel* are synonyms of each other). If you are interested in finding out which unidirectional relations point towards *Fußball*, these can be accessed via \"incoming_relations\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit.incoming_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have sense definitions, harvested from the German Wictionary. These can be accessed with the `wiktionary_paraphrases` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit.wiktionary_paraphrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have also been linked to the English WordNet. The can be accessed with the `ili_records` field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit.ili_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units which are verbs provide information on language use by giving at least one example sentence.\n",
    "They are also annotated with subcategorisation patterns / verb complementations (frames).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schiessen = germanet.get_lexunit_by_id(\"l80272\")\n",
    "schiessen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiessen.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiessen.frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to extract verbs with specific complements of interest. For example, if you're interested in all verbs that allow accusative complements, you can extract them with specific methods, defined in the `Frames` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germanetpy.frames import Frames\n",
    "\n",
    "f = Frames(germanet.frames2lexunits)\n",
    "all_verbs_with_accusative_complement = f.extract_accusative_complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many verbs take accusative complements?\n",
    "len(all_verbs_with_accusative_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are some examples?\n",
    "(all_verbs_with_accusative_complement.pop(), all_verbs_with_accusative_complement.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to extract a large number of examples by applying a filter function\n",
    "If you would like to extract several lexical units or synsets from GermaNet that fulfill certain conditions you can create a filter configuration. For example, filter configurations allow you to search for words of specific\n",
    "Word Classes (e.g. you might be interested in extracting all abstract nouns) or to extract all words that \n",
    "contain a specific subword. To perform a search you have to create a filter configuration object. You have to pass a search string as an argument. All other options have defaults but you can override these defaults to refine your search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can search for *schießen* 'shoot' but ignore upper or lowercasing in different orthforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from germanetpy.filterconfig import Filterconfig\n",
    "\n",
    "filterconfig = Filterconfig(\"schießen\", ignore_case=True)\n",
    "filterconfig.filter_synsets(germanet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now limit the results to synsets of a specific semantic class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germanetpy.synset import WordClass\n",
    "\n",
    "filterconfig.word_classes = [WordClass.Konkurrenz]\n",
    "filtered_result = filterconfig.filter_synsets(germanet)\n",
    "[(synset, synset.word_class) for synset in filtered_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now filter by word category and use only nouns, our result will be empty because there is no entry for 'schießen' as a noun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Besides using full words as search strings we can use regular expressions. This can be very useful if you are interested \n",
    "in words with certain character sequences. The next example shows how to extract all words that end with \"kuchen\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filterconfig = Filterconfig('.*kuchen', regex=True)\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"Found  %d words that end with 'kuchen' in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example extracts all nouns that contain whitespace or a hyphen (useful for example to extract multiword expressions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all nouns that contain whitespace or a hyphen\n",
    "filterconfig = Filterconfig('.+(\\s|-).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d multiword expressions with whitespace or hypen in GermaNet \\n An example of such is: %s \\n Another example is: %s\"\n",
    "      % (len(result), result.pop(), result.pop()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this example extracts verbs that contain 'ff' or 'ss':   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all verbs that contain exactly two 'ss' or two 'ff'\n",
    "filterconfig = Filterconfig('.+(f{2,}|s{2,}).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.verben]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d verbs with double s or double f in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
