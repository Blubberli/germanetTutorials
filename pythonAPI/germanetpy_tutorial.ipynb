{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyGermanet Tutorial\n",
    "\n",
    "The following tutorial shows some examples of how to use the Python API for Germanet. Germanet is a lexical-sematic \n",
    "net that relates German nouns, verbs and adjectives semantically by grouping lexical units that express\n",
    "the same concept into synsets. \n",
    "\n",
    "With the Python API we can extract synsets and lexical units for a given word and inspect different properties and related\n",
    "synsets / lexunits. To use the API you can install it with pip:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install germanetpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from germanetpy.germanet import Germanet\n",
    "from germanetpy.frames import Frames\n",
    "from germanetpy.filterconfig import Filterconfig\n",
    "from germanetpy.synset import WordCategory, WordClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Whenever you want to use the API, the first thing you would do is to create a GermaNet object as this loads the data and provides access to it. The data (all XML files) have to be stored in one directory which has to be specified as the first argument when you construct the GermaNet object. If you want to run this code, put your XML files in a \"germanet_data\" directory in your home directory or change the path to the location on your computer. The API also provides methods to compute semantic similarity / relatedness between words (Synsets). To be able to use all of them you have to provide frequency lists for each word category. These lists can be downloaded from: <!-- where? -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_path = str(Path.home()) + \"/germanet_data\"\n",
    "frequencylist_nouns = data_path + \"/noun_freqs_decow14_16.txt\"\n",
    "germanet = Germanet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The data has been loaded and we can now use the API to extract specific information from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to inspect information for a single word input\n",
    "\n",
    "### Inspect synsets\n",
    "\n",
    "Let's consider the input word *Fußball* 'football'. The following shows how to extract all synsets given an input word. Many words are ambiguous; *Fußball* belongs to two synsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synsets = germanet.get_synsets_by_orthform(\"Fußball\")\n",
    "# the length of the retrieved list is equal to the number of possible senses for a word, in this case 2\n",
    "len(fussball_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string representations include the lexical units, which can be helpful when you want to select\n",
    "a specific meaning for a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in fussball_synsets:\n",
    "    print(synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, let's say we are interested in the sense of *Fußball* which is synonymous with *Fußballspiel* &mdash; that is, the game rather than the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset = germanet.get_synset_by_id('s21624')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every synset has a number of properties that can be extracted. Each synset has a unique id, which is the character\n",
    "'s' followed by a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synset can have one of three possible word categories (verb, noun, adjective). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.word_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the word categories the semantic space is divided into a number of semantic fields. (e.g *Besitz*,\n",
    "*Kommunikation*, *Geschehen*...), called `word_class`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.word_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Synsets are related to other synsets via conceptual relations. The most important relation is the hypernymy\n",
    "/ hyponymy relation. Direct hypernyms of a synset (one level above) and hyponyms (one level below) can be accessed through separate fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.direct_hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.direct_hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All conceptually related synsets are stored in the `relations` field:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation, synsets in fussball_synset.relations.items():\n",
    "    print(\"\\nRelation: %s\" % relation)\n",
    "    print(synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that *Fußball* has exactly one hypernym and several hyponyms. It is also possible to list all <!-- transitive? --> hypernyms\n",
    "from *Fußball* to the top node (root node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.all_hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The level where the *Fußball* synset is attached to the Graph is called its depth. <!-- maybe explain here why the method is called min_depth, namely, a synset can have multiple depths because it can have multiple hypernyms? -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.min_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check whether *Fußball* is the root or a leaf of the GermaNet graph (although of course\n",
    "we already know that this is not case, as it has both hypernyms and hyponyms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.is_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fussball_synset.is_leaf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Use the semantic utils to measure semantic similarity / relatedness\n",
    "You can also use the API to compare a synset with another synset. These methods work only for two synsets that have the same word category, for example for two nouns. There are two different types of similarity measures:\n",
    "- path-based measures\n",
    "- information-content-based measures\n",
    "\n",
    "Path-based measures compute the semantic relatedness between two concepts based on the shortest path between two synsets. The shortest path is the minimal number of nodes you have to walk from the source synset to the target synset. Different measures weigh or normalize the path-length in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first we will look at the simple path distance between two synsets:\n",
    "\n",
    "Let's say you would like to know how *Fußball* and *Tennis* are related within \n",
    "GermaNet. You first need to extract the synset for *Tennis*. Then you can check whether *Tennis* and *Fußball* share any \n",
    "hypernyms and print them.\n",
    "\n",
    "Finally you can extract the shortest path between Fußball and Tennis, i.e. the minimal number of \n",
    "nodes you have to walk from *Fußball* to end up at the synset of *Tennis*. You can also extract the distance between *Fußball* and \n",
    "*Tennis* (in this case the path length). Synsets that are more similar will have a shorter distance than unrelated synsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tennis_synsets = germanet.get_synsets_by_orthform(\"Tennis\")\n",
    "print(tennis_synsets)\n",
    "tennis_synset = tennis_synsets[0]\n",
    "print(fussball_synset.common_hypernyms(tennis_synset))\n",
    "print(fussball_synset.shortest_path(tennis_synset))\n",
    "print(\"Fußball and Tennis have a path distance of %d\" % fussball_synset.shortest_path_distance(tennis_synset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Example for path-based measures\n",
    "\n",
    "The following example shows, how to use the PathBasedRelatedness to check whether Trompete (trumpet) is more related to \n",
    "Posaune (trombone) than to Flöte (flute) and how to disambiguate Flügel (wing, blade, grand) in the context of Klavier (piano). \n",
    "\n",
    "To use the path-based semantic relatedness measures you have to create the corresponding object. This object takes the longest possible shortest distance and a Synset pair that is maximally appart as argument. If not given, those will be computed on the fly but this might take somet time, especially for nouns.\n",
    "\n",
    "As mentioned before, those measures only work for synsets that belong to the same word category, which has to be specified in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first, construct a path-based similarity object\n",
    "from germanetpy.path_based_relatedness_measures import PathBasedRelatedness\n",
    "johannis_wurm = germanet.get_synset_by_id(\"s49774\")\n",
    "leber_trans = germanet.get_synset_by_id(\"s83979\")\n",
    "relatedness_calculator = PathBasedRelatedness(germanet=germanet, category=WordCategory.nomen, max_len=35,\n",
    "                                             max_depth=20, synset_pair=(johannis_wurm, leber_trans))\n",
    "trompete = germanet.get_synsets_by_orthform(\"Trompete\").pop()\n",
    "flöte = germanet.get_synsets_by_orthform(\"Flöte\").pop()\n",
    "posaune = germanet.get_synsets_by_orthform(\"Posaune\").pop()\n",
    "Klavier = germanet.get_synsets_by_orthform(\"Klavier\").pop()\n",
    "Flügel_synsets = germanet.get_synsets_by_orthform(\"Flügel\")\n",
    "trompete_posaune = relatedness_calculator.simple_path(trompete, posaune)\n",
    "trompete_flöte = relatedness_calculator.simple_path(trompete, flöte)\n",
    "\n",
    "print(\"Based on the simple path measure, is Trompete more similar to Posaune, than to Flöte? %s\" % str(trompete_posaune > trompete_flöte))\n",
    "highest_sim_simple = 0.0\n",
    "highest_sim_leacock = 0.0\n",
    "highest_sim_wu = 0.0\n",
    "most_similar_synset = None\n",
    "for synset in Flügel_synsets:\n",
    "    if synset.word_category == WordCategory.nomen:\n",
    "        sim_simple = relatedness_calculator.simple_path(synset, Klavier, normalize=True)\n",
    "        sim_leacock = relatedness_calculator.leacock_chodorow(synset, Klavier, normalize=True)\n",
    "        sim_wu = relatedness_calculator.wu_and_palmer(synset, Klavier, normalize=True)\n",
    "        print(\"\\n These are the similarities between the synset for Klavier and %s : \\n Simple Path : %.2f\\n Leackock and Chodorow: %.2f\\n Wu and Palmer : %.2f\" % (str(synset), sim_simple, sim_leacock, sim_wu));\n",
    "        if sim_simple > highest_sim_simple and sim_leacock > highest_sim_leacock and sim_wu > highest_sim_wu :\n",
    "            highest_sim_simple = sim_simple\n",
    "            highest_sim_leacock = sim_leacock\n",
    "            highest_sim_wu = sim_wu\n",
    "            most_similar_synset = synset\n",
    "print(\"\\nThe most similar synset out of all synsets corresponding to the word 'Flügel' is : %s\" %str(most_similar_synset))\n",
    "print(most_similar_synset.lexunits[0].wiktionary_paraphrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Example for IC-based measures\n",
    "\n",
    "Information-content-based measures augment the structural distances, captured by the taxonomy with word frequencies. Thus the problem of lacking uniform distances in the Graph can be reduced by providing additional information about the typicality of words. The frequencies are used to compute the information content, which graduates concepts from specific to general. If a very specific synset is compared to a very general one, the relatedness will be low. The relatedness is measured based on the information content of the lowest common subsumer (the lowest synset in the hierachy that is hypernym to both synsets that are compared to each other).\n",
    "\n",
    "To use these measures, you have to create an object that takes frequency lists as an additional argument. These lists contain the raw frequencies of the nouns, adjectives and verbs that are in Germanet, based on a very large corpus. You can eihter use the provided frequency lists or use your own lists.\n",
    "\n",
    "The following code snippet shows the advantage of the IC-based measures. While path-based measures would classify the word pair Pflanze 'plant', Tier 'animal' as bein almost as similar as the word pair Roteiche 'red oak' and Steineiche 'holm oak', the IC-based measures distinguish whether two synsets are very general or more specific and consequently assign a higher similarity score to the second word pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from germanetpy.icbased_similarity import ICBasedSimilarity\n",
    "relatedness_nouns = ICBasedSimilarity(germanet=germanet, wordcategory=WordCategory.nomen,\n",
    "                                          path=frequencylist_nouns)\n",
    "pflanze = germanet.get_synset_by_id(\"s44960\")\n",
    "tier = germanet.get_synset_by_id(\"s48805\")\n",
    "sim_leacock_pflanze_tier = relatedness_calculator.leacock_chodorow(pflanze, tier, normalize=True)\n",
    "roteiche = germanet.get_synset_by_id(\"s46054\")\n",
    "steineiche = germanet.get_synset_by_id(\"s46056\")\n",
    "sim_leacock_roteiche_steineiche = relatedness_calculator.leacock_chodorow(roteiche, steineiche, normalize=True)\n",
    "print(\"path-based similarity between Pflanze and Tier: %.2f, between Roteiche and Steineiche %.2f\"% (sim_leacock_pflanze_tier, sim_leacock_roteiche_steineiche))\n",
    "\n",
    "sim_resnik_pflanze_tier = relatedness_nouns.resnik(pflanze, tier, normalize=True)\n",
    "sim_resnik_roteiche_steineiche = relatedness_nouns.resnik(roteiche, steineiche, normalize=True)\n",
    "print(\"ic-based similarity between Pflanze and Tier: %.2f, between Roteiche and Steineiche %.2f\" % (sim_resnik_pflanze_tier, sim_resnik_roteiche_steineiche))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "For a more convenient search through the ontology and the semantic relatedness computation, you can use the GermaNet web application \"Rover\":\n",
    "https://weblicht.sfs.uni-tuebingen.de/rover/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inspect Lexical Units\n",
    "Every synset contains one ore several Lexical Units. The list of Lexical Units (lexunit) can be accessed for any synset. Let's inspect the lexical units for *Fußball* 'football':\n",
    "We have the lexunit *Fußballspiel* 'football match', the lexunit *Fußball* 'football' and the lexunit *Fußballsport* 'soccer ball'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_synset.lexunits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every lexical unit has a number of orthographical forms. There are four different orthographical forms but not every \n",
    "lexical unit has an entry for all of them:\n",
    "* main orth. form: \n",
    "* orth. variation\n",
    "* old orth. form\n",
    "* old orth. variation\n",
    "\n",
    "We can see that the lexunit for *Fußball* only has one orth form, but that one of its related synsets *Fußballklub* 'football club' has the \n",
    "orthographical variation *Fußballkclub*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fussball_unit = germanet.get_lexunit_by_id(\"l29777\")\n",
    "orth_forms = fussball_unit.get_all_orthforms()\n",
    "print(orth_forms)\n",
    "fussballclub_unit = germanet.get_lexunit_by_id(\"l32423\")\n",
    "orth_forms = fussballclub_unit.get_all_orthforms()\n",
    "print(orth_forms)\n",
    "print(fussballclub_unit.orthvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Fußball* is a compound, which are very frequent in the German language. GermaNet stores information about the \n",
    "compound, for example that *Fuß* 'foot' is the modifier and *ball* 'ball' is the head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(fussball_unit.compound_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units are related to other lexical units by different lexical relations. The most common and most general \n",
    "lexical relation is synonymy, but there are other relations annotated as well. For example, for some compounds there has been work\n",
    "on annotating the relation between the compound and the modifier. In this example the compound *Fußball* has the manner \n",
    "functioning of *Fuß*. \n",
    "\n",
    "The relations can be unidirectional (e.g. the relation \"has manner of functioning\" goes from *Fußball*\n",
    "to *Fuß*, but not the other way around. The relation can also be bidirectional, e.g. *Fußball* and *Fußballspiel* are \n",
    "synonyms of each other. If you are interested in finding out which unidirectional relations point towards *Fußball*, these\n",
    "can be accessed via \"incoming_relations\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(fussball_unit.relations)\n",
    "print(fussball_unit.incoming_relations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have sense definitions, harvested from the German Wictionary. These can be accessed with the wiktionary_paraphrases field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(fussball_unit.wiktionary_paraphrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have also been linked to the English WordNet. The can be accessed with the ili_records field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(fussball_unit.ili_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units which are verbs provide information on language use by giving at least one example sentence.\n",
    "They are also annotated with subcategorisation patterns / verb complementations (frames). It is possible to extract\n",
    "verbs with specific complements of interest, for example if you're interested in all verbs that allow accusative complements\n",
    "you can extract them with specific methods, defined in the frames class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schiessen = germanet.get_lexunit_by_id(\"l80272\")\n",
    "print(schiessen)\n",
    "print(schiessen.examples)\n",
    "print(schiessen.frames)\n",
    "f = Frames(germanet.frames2lexunits)\n",
    "all_verbs_with_accusative_complement = f.extract_accusative_complemtent()\n",
    "print(\"There are  %d verbs that can take an accusative complement in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(all_verbs_with_accusative_complement), all_verbs_with_accusative_complement.pop(), all_verbs_with_accusative_complement.pop()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to extract a large number of examples by applying a filter function\n",
    "If you would like to extract several lexical units or synsets from GermaNet that fulfill a certain number of \n",
    "conditions you can create a filter configuration. A filter configuration allows you for example to search for words of specific\n",
    "Word Classes (e.g. you might be interested in extracting all abstract nouns) or you would like to extract all words that \n",
    "contain a specific subword. To do a search you have to create a filter configuration object. You have to pass a search string\n",
    "as an argument. All other options have defaults but you can set them to adapt your search. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we can search for \"schuss\" but we don't want to care about upper or lowercasing and about different orthforms:\n",
    "filterconfig = Filterconfig(\"schießen\", ignore_case=True)\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"filtered result\")\n",
    "for word in result:\n",
    "    print(word)\n",
    "# Let's say we are only interested in synsets of a specific semantic class:\n",
    "filterconfig.word_classes = [WordClass.Konkurrenz]\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"\\nfiltered result\")\n",
    "for word in result:\n",
    "    print(word, word.word_class)\n",
    "# if we now filter by word category and use only nouns, our result will be empty because there is not entry for 'schießen' as a noun:\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"\\nfiltered result\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Besides using full words as search strings we can use regular expressions. This can be very useful if you are interested \n",
    "in words with certain character sequences. The next examples shows how to extract all words that end with \"kuchen\", all \n",
    "words that contain a whitespace or hyphen (useful for example to extract multiword expressions) and how to extract verbs that contain\n",
    "'ff' or 'ss':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extract all words that end with 'kuchen'\n",
    "filterconfig = Filterconfig('.*kuchen', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"Found  %d words that end with 'kuchen' in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n",
    "\n",
    "# extract all words that contain a white space or a hyphen\n",
    "filterconfig = Filterconfig('.+(\\s|-).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d multiword expressions with whitespace or hypen in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n",
    "\n",
    "# extract all verbs that contain exactly two 'ss' or two 'ff'\n",
    "filterconfig = Filterconfig('.+(f{2,}|s{2,}).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.verben]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d verbs with double s or double f in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
